{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "imdb, info = tfds.load(\"imdb_reviews\", with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 25,000 for train, 25,000 for test\n",
    "train_data, test_data = imdb['train'], imdb['test']\n",
    "\n",
    "training_sentences = []\n",
    "training_labels = []\n",
    "\n",
    "testing_sentences = []\n",
    "testing_labels = []\n",
    "\n",
    "for s,l in train_data:\n",
    "    training_sentences.append(s.numpy().decode('utf8'))\n",
    "    training_labels.append(l.numpy())\n",
    "  \n",
    "for s,l in test_data:\n",
    "    testing_sentences.append(s.numpy().decode('utf8'))\n",
    "    testing_labels.append(l.numpy())\n",
    "  \n",
    "\n",
    "training_labels_final = np.array(training_labels)\n",
    "testing_labels_final = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embedding_dim = 16\n",
    "max_length = 120\n",
    "trunc_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "padded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)\n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences,maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i have no idea what the other reviewer is talking about this was a wonderful movie and created a sense of the era that feels like time travel the characters are truly young mary is a strong match for byron claire is juvenile and a tad annoying <OOV> is a convincing beaten down <OOV> all are beautiful curious and <OOV> not the frightening <OOV> they are in gothic br br gothic works as an independent piece of shock film and i loved it for different reasons but this works like a <OOV> and <OOV> film and was from my <OOV> the best capture of what the summer must have felt like romantic yes but completely <OOV> my interest in the\n",
      "----------\n",
      "I have no idea what the other reviewer is talking about- this was a wonderful movie, and created a sense of the era that feels like time travel. The characters are truly young, Mary is a strong match for Byron, Claire is juvenile and a tad annoying, Polidori is a convincing beaten-down sycophant... all are beautiful, curious, and decadent... not the frightening wrecks they are in Gothic.<br /><br />Gothic works as an independent piece of shock film, and I loved it for different reasons, but this works like a Merchant and Ivory film, and was from my readings the best capture of what the summer must have felt like. Romantic, yes, but completely rekindles my interest in the lives of Shelley and Byron every time I think about the film. One of my all-time favorites.\n"
     ]
    }
   ],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
    "\n",
    "print(decode_review(padded[3]))\n",
    "print(\"-\"*10)\n",
    "print(training_sentences[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 120, 16)           160000    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 11526     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 171,533\n",
      "Trainable params: 171,533\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Flatten(), # tf.keras.layers.GlobalAveragePooling1D()\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 120, 16)           160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 102       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 160,109\n",
      "Trainable params: 160,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_GAP = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_GAP.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model_GAP.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.4927 - accuracy: 0.7417 - val_loss: 0.3530 - val_accuracy: 0.8447\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.2395 - accuracy: 0.9072 - val_loss: 0.3715 - val_accuracy: 0.8387\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.0938 - accuracy: 0.9768 - val_loss: 0.4452 - val_accuracy: 0.8264\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.0257 - accuracy: 0.9968 - val_loss: 0.5151 - val_accuracy: 0.8286\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.0087 - accuracy: 0.9990 - val_loss: 0.5826 - val_accuracy: 0.8250\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 0.6335 - val_accuracy: 0.8242\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6920 - val_accuracy: 0.8228\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 5.2106e-04 - accuracy: 1.0000 - val_loss: 0.7243 - val_accuracy: 0.8262\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 2.9192e-04 - accuracy: 1.0000 - val_loss: 0.7632 - val_accuracy: 0.8264\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 1.7473e-04 - accuracy: 1.0000 - val_loss: 0.7923 - val_accuracy: 0.8272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5570517a60>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "model.fit(padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))\n",
    "\n",
    "# overfitting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.5580 - accuracy: 0.7419 - val_loss: 0.3872 - val_accuracy: 0.8426\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.3350 - accuracy: 0.8595 - val_loss: 0.3308 - val_accuracy: 0.8581\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.2731 - accuracy: 0.8891 - val_loss: 0.3278 - val_accuracy: 0.8596\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.2367 - accuracy: 0.9083 - val_loss: 0.3434 - val_accuracy: 0.8535\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.2107 - accuracy: 0.9202 - val_loss: 0.3610 - val_accuracy: 0.8499\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1902 - accuracy: 0.9303 - val_loss: 0.3873 - val_accuracy: 0.8434\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.1723 - accuracy: 0.9376 - val_loss: 0.4154 - val_accuracy: 0.8372\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.1565 - accuracy: 0.9452 - val_loss: 0.4462 - val_accuracy: 0.8348\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1424 - accuracy: 0.9514 - val_loss: 0.4806 - val_accuracy: 0.8304\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.1306 - accuracy: 0.9564 - val_loss: 0.5158 - val_accuracy: 0.8284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f556074ad90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_GAP.fit(padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))\n",
    "\n",
    "# GlobalAveragePooling1D shows liitle bit more of accurancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "e = model.layers[0]\n",
    "weights = e.get_weights()[0]\n",
    "print(weights.shape) # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for word_num in range(1, vocab_size):\n",
    "    word = reverse_word_index[word_num]\n",
    "    embeddings = weights[word_num]\n",
    "    out_m.write(word + \"\\n\")\n",
    "    out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11, 64, 102, 12, 7, 478, 1200]]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I really think this is amazing. honest.\"\n",
    "sequence = tokenizer.texts_to_sequences([sentence])\n",
    "print(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go to 'http://projector.tensorflow.org/'\n",
    "# and try to upload .tsv file to visualize the data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
