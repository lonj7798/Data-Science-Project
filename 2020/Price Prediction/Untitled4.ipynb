{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing stores (due to limit):  (480160, 3)\n",
      "Total # of stores that exceeds 160 is 997\n",
      "After removing stores (due to limit):  (432671, 3)\n",
      "# of train store open/out of business:  906 91\n",
      "2018-03-21 00:00:00\n",
      "2018-01-17 00:00:00\n",
      "2018-03-23 00:00:00\n",
      "2018-03-23 00:00:00\n",
      "# of test store open/out of business:  196 4\n",
      "[0]\ttrain-mae:70736.1\ttest-mae:70969.4\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 300 rounds.\n",
      "[1]\ttrain-mae:67466.9\ttest-mae:67839.3\n",
      "[2]\ttrain-mae:64360.5\ttest-mae:64749.1\n",
      "[3]\ttrain-mae:61335.7\ttest-mae:61840\n",
      "[4]\ttrain-mae:58528.9\ttest-mae:59157.8\n",
      "[5]\ttrain-mae:55881.6\ttest-mae:56558.5\n",
      "[6]\ttrain-mae:53206.3\ttest-mae:54212.1\n",
      "[7]\ttrain-mae:50742.2\ttest-mae:52047\n",
      "[8]\ttrain-mae:48370.5\ttest-mae:49897.3\n",
      "[9]\ttrain-mae:46172.1\ttest-mae:47855.8\n",
      "[10]\ttrain-mae:44135.1\ttest-mae:45928.4\n",
      "[11]\ttrain-mae:42137.9\ttest-mae:44137.5\n",
      "[12]\ttrain-mae:40301.7\ttest-mae:42435\n",
      "[13]\ttrain-mae:38499\ttest-mae:40716.3\n",
      "[14]\ttrain-mae:36786.7\ttest-mae:39311.2\n",
      "[15]\ttrain-mae:35176.6\ttest-mae:37837.8\n",
      "[16]\ttrain-mae:33584.3\ttest-mae:36350.8\n",
      "[17]\ttrain-mae:32142.9\ttest-mae:34886.4\n",
      "[18]\ttrain-mae:30759.5\ttest-mae:33697.6\n",
      "[19]\ttrain-mae:29418.7\ttest-mae:32435.8\n",
      "[20]\ttrain-mae:28141\ttest-mae:31319.5\n",
      "[21]\ttrain-mae:26936.4\ttest-mae:30354.4\n",
      "[22]\ttrain-mae:25765.9\ttest-mae:29229.2\n",
      "[23]\ttrain-mae:24669.2\ttest-mae:28159.4\n",
      "[24]\ttrain-mae:23627.8\ttest-mae:27345.5\n",
      "[25]\ttrain-mae:22609.3\ttest-mae:26487.4\n",
      "[26]\ttrain-mae:21661.2\ttest-mae:25646.7\n",
      "[27]\ttrain-mae:20784.6\ttest-mae:24963.8\n",
      "[28]\ttrain-mae:19947.1\ttest-mae:24311.4\n",
      "[29]\ttrain-mae:19143.7\ttest-mae:23740.8\n",
      "[30]\ttrain-mae:18392.6\ttest-mae:23096.5\n",
      "[31]\ttrain-mae:17684.6\ttest-mae:22583.1\n",
      "[32]\ttrain-mae:16991.4\ttest-mae:21943.6\n",
      "[33]\ttrain-mae:16335.3\ttest-mae:21403.2\n",
      "[34]\ttrain-mae:15701.4\ttest-mae:20929.7\n",
      "[35]\ttrain-mae:15098.9\ttest-mae:20503.4\n",
      "[36]\ttrain-mae:14550.2\ttest-mae:20130.8\n",
      "[37]\ttrain-mae:14024.5\ttest-mae:19629.3\n",
      "[38]\ttrain-mae:13511.8\ttest-mae:19294.9\n",
      "[39]\ttrain-mae:13029.3\ttest-mae:18916.9\n",
      "[40]\ttrain-mae:12583.5\ttest-mae:18583.5\n",
      "[41]\ttrain-mae:12142.4\ttest-mae:18254.5\n",
      "[42]\ttrain-mae:11751\ttest-mae:18029\n",
      "[43]\ttrain-mae:11366.4\ttest-mae:17790.4\n",
      "[44]\ttrain-mae:10990.3\ttest-mae:17593.4\n",
      "[45]\ttrain-mae:10632\ttest-mae:17427.3\n",
      "[46]\ttrain-mae:10294.4\ttest-mae:17158.5\n",
      "[47]\ttrain-mae:10000.4\ttest-mae:17016.9\n",
      "[48]\ttrain-mae:9684.48\ttest-mae:16835.7\n",
      "[49]\ttrain-mae:9377.46\ttest-mae:16586.1\n",
      "[50]\ttrain-mae:9096.53\ttest-mae:16378.3\n",
      "[51]\ttrain-mae:8873.4\ttest-mae:16236.7\n",
      "[52]\ttrain-mae:8607.65\ttest-mae:16042.2\n",
      "[53]\ttrain-mae:8342.27\ttest-mae:15833.8\n",
      "[54]\ttrain-mae:8116.87\ttest-mae:15706.7\n",
      "[55]\ttrain-mae:7903.44\ttest-mae:15602.3\n",
      "[56]\ttrain-mae:7678.71\ttest-mae:15446.4\n",
      "[57]\ttrain-mae:7476.49\ttest-mae:15367.5\n",
      "[58]\ttrain-mae:7277.65\ttest-mae:15228.9\n",
      "[59]\ttrain-mae:7092.03\ttest-mae:15039.5\n",
      "[60]\ttrain-mae:6923.88\ttest-mae:14925.2\n",
      "[61]\ttrain-mae:6778.37\ttest-mae:14854.4\n",
      "[62]\ttrain-mae:6628.56\ttest-mae:14736.6\n",
      "[63]\ttrain-mae:6479.95\ttest-mae:14650.2\n",
      "[64]\ttrain-mae:6360.49\ttest-mae:14602.4\n",
      "[65]\ttrain-mae:6225.96\ttest-mae:14551\n",
      "[66]\ttrain-mae:6132.19\ttest-mae:14502.1\n",
      "[67]\ttrain-mae:6006.89\ttest-mae:14374.5\n",
      "[68]\ttrain-mae:5912.04\ttest-mae:14340\n",
      "[69]\ttrain-mae:5800.2\ttest-mae:14264.5\n",
      "[70]\ttrain-mae:5715.55\ttest-mae:14199.3\n",
      "[71]\ttrain-mae:5619.12\ttest-mae:14142.5\n",
      "[72]\ttrain-mae:5514.22\ttest-mae:14115.5\n",
      "[73]\ttrain-mae:5401.17\ttest-mae:14064.2\n",
      "[74]\ttrain-mae:5310.54\ttest-mae:14027.9\n",
      "[75]\ttrain-mae:5230.93\ttest-mae:13983.4\n",
      "[76]\ttrain-mae:5151.62\ttest-mae:13958.8\n",
      "[77]\ttrain-mae:5064.38\ttest-mae:13910.6\n",
      "[78]\ttrain-mae:5005.74\ttest-mae:13873.9\n",
      "[79]\ttrain-mae:4937.38\ttest-mae:13835.1\n",
      "[80]\ttrain-mae:4858.63\ttest-mae:13797\n",
      "[81]\ttrain-mae:4792.41\ttest-mae:13788.6\n",
      "[82]\ttrain-mae:4719.79\ttest-mae:13748.2\n",
      "[83]\ttrain-mae:4638.17\ttest-mae:13691.3\n",
      "[84]\ttrain-mae:4570.63\ttest-mae:13649.3\n",
      "[85]\ttrain-mae:4506.62\ttest-mae:13646.4\n",
      "[86]\ttrain-mae:4436.77\ttest-mae:13646\n",
      "[87]\ttrain-mae:4388.9\ttest-mae:13611.1\n",
      "[88]\ttrain-mae:4325.75\ttest-mae:13582.1\n",
      "[89]\ttrain-mae:4263.13\ttest-mae:13516\n",
      "[90]\ttrain-mae:4224.77\ttest-mae:13509.8\n",
      "[91]\ttrain-mae:4176.42\ttest-mae:13469.6\n",
      "[92]\ttrain-mae:4130.51\ttest-mae:13457.4\n",
      "[93]\ttrain-mae:4075.11\ttest-mae:13437\n",
      "[94]\ttrain-mae:4043.3\ttest-mae:13413\n",
      "[95]\ttrain-mae:3981.8\ttest-mae:13394.7\n",
      "[96]\ttrain-mae:3946.12\ttest-mae:13385.7\n",
      "[97]\ttrain-mae:3893.69\ttest-mae:13396.2\n",
      "[98]\ttrain-mae:3838.88\ttest-mae:13391.3\n",
      "[99]\ttrain-mae:3796.9\ttest-mae:13403.5\n",
      "[100]\ttrain-mae:3749.43\ttest-mae:13403.9\n",
      "[101]\ttrain-mae:3711.01\ttest-mae:13395.2\n",
      "[102]\ttrain-mae:3682.55\ttest-mae:13378.1\n",
      "[103]\ttrain-mae:3629.77\ttest-mae:13370.4\n",
      "[104]\ttrain-mae:3596.4\ttest-mae:13354.5\n",
      "[105]\ttrain-mae:3560.86\ttest-mae:13340.9\n",
      "[106]\ttrain-mae:3535.54\ttest-mae:13335.2\n",
      "[107]\ttrain-mae:3512.91\ttest-mae:13335.8\n",
      "[108]\ttrain-mae:3460.9\ttest-mae:13331.1\n",
      "[109]\ttrain-mae:3440.24\ttest-mae:13322.5\n",
      "[110]\ttrain-mae:3413.6\ttest-mae:13312.3\n",
      "[111]\ttrain-mae:3377.82\ttest-mae:13316.2\n",
      "[112]\ttrain-mae:3356.77\ttest-mae:13306.8\n",
      "[113]\ttrain-mae:3319.86\ttest-mae:13292.4\n",
      "[114]\ttrain-mae:3290.23\ttest-mae:13311.6\n",
      "[115]\ttrain-mae:3259.54\ttest-mae:13301.7\n",
      "[116]\ttrain-mae:3230.11\ttest-mae:13313.3\n",
      "[117]\ttrain-mae:3192.05\ttest-mae:13320.2\n",
      "[118]\ttrain-mae:3165.3\ttest-mae:13319.2\n",
      "[119]\ttrain-mae:3129.49\ttest-mae:13308.9\n",
      "[120]\ttrain-mae:3108.25\ttest-mae:13307.7\n",
      "[121]\ttrain-mae:3090.09\ttest-mae:13290.6\n",
      "[122]\ttrain-mae:3064.9\ttest-mae:13291.3\n",
      "[123]\ttrain-mae:3051.21\ttest-mae:13289.6\n",
      "[124]\ttrain-mae:3031.79\ttest-mae:13282.8\n",
      "[125]\ttrain-mae:2996.14\ttest-mae:13268.6\n",
      "[126]\ttrain-mae:2969.19\ttest-mae:13269.9\n",
      "[127]\ttrain-mae:2932.55\ttest-mae:13267.6\n",
      "[128]\ttrain-mae:2903.65\ttest-mae:13249.3\n",
      "[129]\ttrain-mae:2882.45\ttest-mae:13245.1\n",
      "[130]\ttrain-mae:2863.01\ttest-mae:13250.4\n",
      "[131]\ttrain-mae:2847.78\ttest-mae:13246.9\n",
      "[132]\ttrain-mae:2826.92\ttest-mae:13253.6\n",
      "[133]\ttrain-mae:2810.17\ttest-mae:13253.3\n",
      "[134]\ttrain-mae:2795.85\ttest-mae:13248.7\n",
      "[135]\ttrain-mae:2768.35\ttest-mae:13248.2\n",
      "[136]\ttrain-mae:2747.49\ttest-mae:13240.8\n",
      "[137]\ttrain-mae:2730.39\ttest-mae:13227.1\n",
      "[138]\ttrain-mae:2714.98\ttest-mae:13232.7\n",
      "[139]\ttrain-mae:2699.78\ttest-mae:13229\n",
      "[140]\ttrain-mae:2684.38\ttest-mae:13226\n",
      "[141]\ttrain-mae:2672.43\ttest-mae:13220.5\n",
      "[142]\ttrain-mae:2659.07\ttest-mae:13210.7\n",
      "[143]\ttrain-mae:2633.44\ttest-mae:13185.4\n",
      "[144]\ttrain-mae:2624.6\ttest-mae:13184.6\n",
      "[145]\ttrain-mae:2606.75\ttest-mae:13185.2\n",
      "[146]\ttrain-mae:2579.61\ttest-mae:13181.4\n",
      "[147]\ttrain-mae:2557.54\ttest-mae:13196.6\n",
      "[148]\ttrain-mae:2543.8\ttest-mae:13190.5\n",
      "[149]\ttrain-mae:2525.21\ttest-mae:13173.1\n",
      "[150]\ttrain-mae:2510.88\ttest-mae:13170.8\n",
      "[151]\ttrain-mae:2498.6\ttest-mae:13174.8\n",
      "[152]\ttrain-mae:2467.72\ttest-mae:13179.9\n",
      "[153]\ttrain-mae:2441.9\ttest-mae:13165.6\n",
      "[154]\ttrain-mae:2433.68\ttest-mae:13156.7\n",
      "[155]\ttrain-mae:2420.59\ttest-mae:13151.2\n",
      "[156]\ttrain-mae:2408.83\ttest-mae:13154\n",
      "[157]\ttrain-mae:2395.91\ttest-mae:13146.6\n",
      "[158]\ttrain-mae:2383.95\ttest-mae:13151.5\n",
      "[159]\ttrain-mae:2368.2\ttest-mae:13159.3\n",
      "[160]\ttrain-mae:2339.43\ttest-mae:13163.8\n",
      "[161]\ttrain-mae:2327.46\ttest-mae:13165.2\n",
      "[162]\ttrain-mae:2306.68\ttest-mae:13174.1\n",
      "[163]\ttrain-mae:2291.27\ttest-mae:13170.8\n",
      "[164]\ttrain-mae:2277.7\ttest-mae:13189.6\n",
      "[165]\ttrain-mae:2257.89\ttest-mae:13196.9\n",
      "[166]\ttrain-mae:2246.44\ttest-mae:13199.2\n",
      "[167]\ttrain-mae:2232\ttest-mae:13207.5\n",
      "[168]\ttrain-mae:2213.27\ttest-mae:13206.4\n",
      "[169]\ttrain-mae:2195.7\ttest-mae:13203\n",
      "[170]\ttrain-mae:2170.02\ttest-mae:13197.6\n",
      "[171]\ttrain-mae:2162.38\ttest-mae:13197.6\n",
      "[172]\ttrain-mae:2130.72\ttest-mae:13191.8\n",
      "[173]\ttrain-mae:2120.97\ttest-mae:13190.9\n",
      "[174]\ttrain-mae:2103.49\ttest-mae:13189.8\n",
      "[175]\ttrain-mae:2090.18\ttest-mae:13190.1\n",
      "[176]\ttrain-mae:2083.24\ttest-mae:13195.6\n",
      "[177]\ttrain-mae:2071.22\ttest-mae:13191\n",
      "[178]\ttrain-mae:2059.56\ttest-mae:13188.1\n",
      "[179]\ttrain-mae:2054.3\ttest-mae:13188.9\n",
      "[180]\ttrain-mae:2047.27\ttest-mae:13190\n",
      "[181]\ttrain-mae:2040.94\ttest-mae:13185.2\n",
      "[182]\ttrain-mae:2018.12\ttest-mae:13186.6\n",
      "[183]\ttrain-mae:2005.08\ttest-mae:13189.5\n",
      "[184]\ttrain-mae:1992.64\ttest-mae:13190.3\n",
      "[185]\ttrain-mae:1979.89\ttest-mae:13194.5\n",
      "[186]\ttrain-mae:1966.4\ttest-mae:13193.3\n",
      "[187]\ttrain-mae:1952.76\ttest-mae:13198.5\n",
      "[188]\ttrain-mae:1929.91\ttest-mae:13201.6\n",
      "[189]\ttrain-mae:1917.89\ttest-mae:13203.1\n",
      "[190]\ttrain-mae:1909.93\ttest-mae:13199.7\n",
      "[191]\ttrain-mae:1899.43\ttest-mae:13193.4\n",
      "[192]\ttrain-mae:1884.22\ttest-mae:13187.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[193]\ttrain-mae:1871.92\ttest-mae:13188.6\n",
      "[194]\ttrain-mae:1859.6\ttest-mae:13189.9\n",
      "[195]\ttrain-mae:1849.65\ttest-mae:13197.1\n",
      "[196]\ttrain-mae:1833.67\ttest-mae:13195.4\n",
      "[197]\ttrain-mae:1817.59\ttest-mae:13190.4\n",
      "[198]\ttrain-mae:1807.73\ttest-mae:13195.3\n",
      "[199]\ttrain-mae:1792.75\ttest-mae:13190.9\n",
      "[200]\ttrain-mae:1776.31\ttest-mae:13187.2\n",
      "[201]\ttrain-mae:1755.4\ttest-mae:13200.6\n",
      "[202]\ttrain-mae:1732.02\ttest-mae:13202\n",
      "[203]\ttrain-mae:1719.27\ttest-mae:13196\n",
      "[204]\ttrain-mae:1710.35\ttest-mae:13193.1\n",
      "[205]\ttrain-mae:1698.4\ttest-mae:13190.3\n",
      "[206]\ttrain-mae:1688.66\ttest-mae:13196\n",
      "[207]\ttrain-mae:1669.25\ttest-mae:13187\n",
      "[208]\ttrain-mae:1657.79\ttest-mae:13179.6\n",
      "[209]\ttrain-mae:1650.43\ttest-mae:13180\n",
      "[210]\ttrain-mae:1637.78\ttest-mae:13183\n",
      "[211]\ttrain-mae:1632.49\ttest-mae:13184\n",
      "[212]\ttrain-mae:1622.87\ttest-mae:13190\n",
      "[213]\ttrain-mae:1605.57\ttest-mae:13193.5\n",
      "[214]\ttrain-mae:1599.85\ttest-mae:13197.1\n",
      "[215]\ttrain-mae:1592.12\ttest-mae:13191.8\n",
      "[216]\ttrain-mae:1571.25\ttest-mae:13192.2\n",
      "[217]\ttrain-mae:1559.61\ttest-mae:13184.2\n",
      "[218]\ttrain-mae:1536.63\ttest-mae:13193.8\n",
      "[219]\ttrain-mae:1528.51\ttest-mae:13191.4\n",
      "[220]\ttrain-mae:1521.05\ttest-mae:13189.2\n",
      "[221]\ttrain-mae:1511.04\ttest-mae:13192.9\n",
      "[222]\ttrain-mae:1501.86\ttest-mae:13196.3\n",
      "[223]\ttrain-mae:1486.17\ttest-mae:13195.7\n",
      "[224]\ttrain-mae:1474.3\ttest-mae:13191\n",
      "[225]\ttrain-mae:1461.09\ttest-mae:13188\n",
      "[226]\ttrain-mae:1449.63\ttest-mae:13193.9\n",
      "[227]\ttrain-mae:1434.8\ttest-mae:13183.8\n",
      "[228]\ttrain-mae:1430.34\ttest-mae:13184.4\n",
      "[229]\ttrain-mae:1418.85\ttest-mae:13186\n",
      "[230]\ttrain-mae:1410.52\ttest-mae:13186.1\n",
      "[231]\ttrain-mae:1393.26\ttest-mae:13189\n",
      "[232]\ttrain-mae:1384.95\ttest-mae:13190.5\n",
      "[233]\ttrain-mae:1375.48\ttest-mae:13190.4\n",
      "[234]\ttrain-mae:1361.61\ttest-mae:13187.3\n",
      "[235]\ttrain-mae:1355.33\ttest-mae:13189.1\n",
      "[236]\ttrain-mae:1344.55\ttest-mae:13189.3\n",
      "[237]\ttrain-mae:1329.47\ttest-mae:13193.7\n",
      "[238]\ttrain-mae:1321.57\ttest-mae:13196.2\n",
      "[239]\ttrain-mae:1311.92\ttest-mae:13200.6\n",
      "[240]\ttrain-mae:1305.51\ttest-mae:13199.7\n",
      "[241]\ttrain-mae:1296.21\ttest-mae:13197\n",
      "[242]\ttrain-mae:1283.64\ttest-mae:13197.7\n",
      "[243]\ttrain-mae:1267.39\ttest-mae:13197.4\n",
      "[244]\ttrain-mae:1260.41\ttest-mae:13198.7\n",
      "[245]\ttrain-mae:1252.67\ttest-mae:13200.2\n",
      "[246]\ttrain-mae:1246.92\ttest-mae:13198.4\n",
      "[247]\ttrain-mae:1235.24\ttest-mae:13202.9\n",
      "[248]\ttrain-mae:1227.61\ttest-mae:13210\n",
      "[249]\ttrain-mae:1220.12\ttest-mae:13209.1\n",
      "[250]\ttrain-mae:1212.58\ttest-mae:13207.1\n",
      "[251]\ttrain-mae:1209.63\ttest-mae:13203.4\n",
      "[252]\ttrain-mae:1203.11\ttest-mae:13203.8\n",
      "[253]\ttrain-mae:1188.26\ttest-mae:13205.4\n",
      "[254]\ttrain-mae:1175.23\ttest-mae:13208\n",
      "[255]\ttrain-mae:1165.35\ttest-mae:13210.3\n",
      "[256]\ttrain-mae:1161.6\ttest-mae:13213.3\n",
      "[257]\ttrain-mae:1153.79\ttest-mae:13212.8\n",
      "[258]\ttrain-mae:1142.19\ttest-mae:13219\n",
      "[259]\ttrain-mae:1129.65\ttest-mae:13219.5\n",
      "[260]\ttrain-mae:1118.91\ttest-mae:13222.5\n",
      "[261]\ttrain-mae:1112.2\ttest-mae:13223.7\n",
      "[262]\ttrain-mae:1101.3\ttest-mae:13226.1\n",
      "[263]\ttrain-mae:1094.06\ttest-mae:13230.3\n",
      "[264]\ttrain-mae:1085.96\ttest-mae:13229.7\n",
      "[265]\ttrain-mae:1078.82\ttest-mae:13234.2\n",
      "[266]\ttrain-mae:1066.47\ttest-mae:13232.9\n",
      "[267]\ttrain-mae:1057.88\ttest-mae:13235\n",
      "[268]\ttrain-mae:1049.27\ttest-mae:13240.9\n",
      "[269]\ttrain-mae:1034.96\ttest-mae:13234.7\n",
      "[270]\ttrain-mae:1028.52\ttest-mae:13239.9\n",
      "[271]\ttrain-mae:1022.18\ttest-mae:13239.2\n",
      "[272]\ttrain-mae:1012.61\ttest-mae:13239.8\n",
      "[273]\ttrain-mae:999.116\ttest-mae:13240.8\n",
      "[274]\ttrain-mae:991.237\ttest-mae:13244\n",
      "[275]\ttrain-mae:985.992\ttest-mae:13242.7\n",
      "[276]\ttrain-mae:980.253\ttest-mae:13243.4\n",
      "[277]\ttrain-mae:967.417\ttest-mae:13249.5\n",
      "[278]\ttrain-mae:959.532\ttest-mae:13252.5\n",
      "[279]\ttrain-mae:952.781\ttest-mae:13254.7\n",
      "[280]\ttrain-mae:945.854\ttest-mae:13256.8\n",
      "[281]\ttrain-mae:940.301\ttest-mae:13255.5\n",
      "[282]\ttrain-mae:930.791\ttest-mae:13255.7\n",
      "[283]\ttrain-mae:925.086\ttest-mae:13252.8\n",
      "[284]\ttrain-mae:918.94\ttest-mae:13259.8\n",
      "[285]\ttrain-mae:907.915\ttest-mae:13265.4\n",
      "[286]\ttrain-mae:898.786\ttest-mae:13270.1\n",
      "[287]\ttrain-mae:892.033\ttest-mae:13271.3\n",
      "[288]\ttrain-mae:886.984\ttest-mae:13275.2\n",
      "[289]\ttrain-mae:879.277\ttest-mae:13278\n",
      "[290]\ttrain-mae:873.801\ttest-mae:13280.8\n",
      "[291]\ttrain-mae:867.688\ttest-mae:13283.2\n",
      "[292]\ttrain-mae:862.353\ttest-mae:13282.9\n",
      "[293]\ttrain-mae:857.241\ttest-mae:13281.1\n",
      "[294]\ttrain-mae:848.004\ttest-mae:13279.4\n",
      "[295]\ttrain-mae:842.948\ttest-mae:13280.9\n",
      "[296]\ttrain-mae:833.102\ttest-mae:13280.4\n",
      "[297]\ttrain-mae:824.533\ttest-mae:13277.6\n",
      "[298]\ttrain-mae:819.655\ttest-mae:13280.3\n",
      "[299]\ttrain-mae:811.502\ttest-mae:13283.2\n",
      "[300]\ttrain-mae:809.359\ttest-mae:13285.5\n",
      "[301]\ttrain-mae:801.085\ttest-mae:13286.4\n",
      "[302]\ttrain-mae:795.389\ttest-mae:13291.6\n",
      "[303]\ttrain-mae:786.761\ttest-mae:13292.4\n",
      "[304]\ttrain-mae:783.884\ttest-mae:13293.3\n",
      "[305]\ttrain-mae:777.242\ttest-mae:13292.4\n",
      "[306]\ttrain-mae:769.014\ttest-mae:13291.3\n",
      "[307]\ttrain-mae:764.731\ttest-mae:13291.3\n",
      "[308]\ttrain-mae:757.392\ttest-mae:13293\n",
      "[309]\ttrain-mae:752.625\ttest-mae:13295.3\n",
      "[310]\ttrain-mae:747.035\ttest-mae:13297.2\n",
      "[311]\ttrain-mae:739.623\ttest-mae:13297.9\n",
      "[312]\ttrain-mae:733.193\ttest-mae:13297.4\n",
      "[313]\ttrain-mae:726.586\ttest-mae:13299.3\n",
      "[314]\ttrain-mae:717.771\ttest-mae:13299.2\n",
      "[315]\ttrain-mae:712.373\ttest-mae:13298.1\n",
      "[316]\ttrain-mae:710.849\ttest-mae:13297.2\n",
      "[317]\ttrain-mae:703.382\ttest-mae:13295.2\n",
      "[318]\ttrain-mae:699.584\ttest-mae:13297\n",
      "[319]\ttrain-mae:689.646\ttest-mae:13298.2\n",
      "[320]\ttrain-mae:682.939\ttest-mae:13298.4\n",
      "[321]\ttrain-mae:678.529\ttest-mae:13300.9\n",
      "[322]\ttrain-mae:674.26\ttest-mae:13299.3\n",
      "[323]\ttrain-mae:671.67\ttest-mae:13298.7\n",
      "[324]\ttrain-mae:665.236\ttest-mae:13304.4\n",
      "[325]\ttrain-mae:659.967\ttest-mae:13305.7\n",
      "[326]\ttrain-mae:654.97\ttest-mae:13302.8\n",
      "[327]\ttrain-mae:649.653\ttest-mae:13302.1\n",
      "[328]\ttrain-mae:646.137\ttest-mae:13301.2\n",
      "[329]\ttrain-mae:642.6\ttest-mae:13302.8\n",
      "[330]\ttrain-mae:639.896\ttest-mae:13303.7\n",
      "[331]\ttrain-mae:636.547\ttest-mae:13303.3\n",
      "[332]\ttrain-mae:628.394\ttest-mae:13301.6\n",
      "[333]\ttrain-mae:625.237\ttest-mae:13302.5\n",
      "[334]\ttrain-mae:622.881\ttest-mae:13303.4\n",
      "[335]\ttrain-mae:617.213\ttest-mae:13303.2\n",
      "[336]\ttrain-mae:612.713\ttest-mae:13306.4\n",
      "[337]\ttrain-mae:609.981\ttest-mae:13308.7\n",
      "[338]\ttrain-mae:604.323\ttest-mae:13307.9\n",
      "[339]\ttrain-mae:601.573\ttest-mae:13307.5\n",
      "[340]\ttrain-mae:598.903\ttest-mae:13309.1\n",
      "[341]\ttrain-mae:591.766\ttest-mae:13306.1\n",
      "[342]\ttrain-mae:589.412\ttest-mae:13305.7\n",
      "[343]\ttrain-mae:585.99\ttest-mae:13305.1\n",
      "[344]\ttrain-mae:579.202\ttest-mae:13304.9\n",
      "[345]\ttrain-mae:575.319\ttest-mae:13305.6\n",
      "[346]\ttrain-mae:568.203\ttest-mae:13303.7\n",
      "[347]\ttrain-mae:565.03\ttest-mae:13301.7\n",
      "[348]\ttrain-mae:559.543\ttest-mae:13301.9\n",
      "[349]\ttrain-mae:555.199\ttest-mae:13299.5\n",
      "[350]\ttrain-mae:552.238\ttest-mae:13299.7\n",
      "[351]\ttrain-mae:545.513\ttest-mae:13300.1\n",
      "[352]\ttrain-mae:542.791\ttest-mae:13301.1\n",
      "[353]\ttrain-mae:536.99\ttest-mae:13302.9\n",
      "[354]\ttrain-mae:533.839\ttest-mae:13303.1\n",
      "[355]\ttrain-mae:528.615\ttest-mae:13306.6\n",
      "[356]\ttrain-mae:522.224\ttest-mae:13306.3\n",
      "[357]\ttrain-mae:519.141\ttest-mae:13306.7\n",
      "[358]\ttrain-mae:514.578\ttest-mae:13308.4\n",
      "[359]\ttrain-mae:507.289\ttest-mae:13311.3\n",
      "[360]\ttrain-mae:501.848\ttest-mae:13308.3\n",
      "[361]\ttrain-mae:499.043\ttest-mae:13308.3\n",
      "[362]\ttrain-mae:494.045\ttest-mae:13307.9\n",
      "[363]\ttrain-mae:490.692\ttest-mae:13306.9\n",
      "[364]\ttrain-mae:487.619\ttest-mae:13307.8\n",
      "[365]\ttrain-mae:481.948\ttest-mae:13312.1\n",
      "[366]\ttrain-mae:477.513\ttest-mae:13311.4\n",
      "[367]\ttrain-mae:471.007\ttest-mae:13312.6\n",
      "[368]\ttrain-mae:465.975\ttest-mae:13310.7\n",
      "[369]\ttrain-mae:463.484\ttest-mae:13313.8\n",
      "[370]\ttrain-mae:460.872\ttest-mae:13314.4\n",
      "[371]\ttrain-mae:455.283\ttest-mae:13317.6\n",
      "[372]\ttrain-mae:453.004\ttest-mae:13318\n",
      "[373]\ttrain-mae:447.984\ttest-mae:13317\n",
      "[374]\ttrain-mae:445.158\ttest-mae:13318\n",
      "[375]\ttrain-mae:442.226\ttest-mae:13319.7\n",
      "[376]\ttrain-mae:437.462\ttest-mae:13322.4\n",
      "[377]\ttrain-mae:434.704\ttest-mae:13321.5\n",
      "[378]\ttrain-mae:431.743\ttest-mae:13325.2\n",
      "[379]\ttrain-mae:428.363\ttest-mae:13325.8\n",
      "[380]\ttrain-mae:424.562\ttest-mae:13326.7\n",
      "[381]\ttrain-mae:419.881\ttest-mae:13324.3\n",
      "[382]\ttrain-mae:417.624\ttest-mae:13324.4\n",
      "[383]\ttrain-mae:414.64\ttest-mae:13325\n",
      "[384]\ttrain-mae:410.881\ttest-mae:13325.3\n",
      "[385]\ttrain-mae:408.603\ttest-mae:13324\n",
      "[386]\ttrain-mae:402.81\ttest-mae:13326.3\n",
      "[387]\ttrain-mae:400.946\ttest-mae:13326.1\n",
      "[388]\ttrain-mae:397.408\ttest-mae:13327.1\n",
      "[389]\ttrain-mae:395.657\ttest-mae:13326.4\n",
      "[390]\ttrain-mae:393.47\ttest-mae:13325.8\n",
      "[391]\ttrain-mae:390.789\ttest-mae:13327.6\n",
      "[392]\ttrain-mae:388.11\ttest-mae:13327.9\n",
      "[393]\ttrain-mae:385.113\ttest-mae:13327.2\n",
      "[394]\ttrain-mae:381.35\ttest-mae:13328.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[395]\ttrain-mae:376.716\ttest-mae:13333.8\n",
      "[396]\ttrain-mae:373.971\ttest-mae:13334.4\n",
      "[397]\ttrain-mae:371.946\ttest-mae:13334\n",
      "[398]\ttrain-mae:366.334\ttest-mae:13332.3\n",
      "[399]\ttrain-mae:363.114\ttest-mae:13332.4\n",
      "[400]\ttrain-mae:359.383\ttest-mae:13331.9\n",
      "[401]\ttrain-mae:357.72\ttest-mae:13332.2\n",
      "[402]\ttrain-mae:356.815\ttest-mae:13332\n",
      "[403]\ttrain-mae:354.496\ttest-mae:13333.4\n",
      "[404]\ttrain-mae:351.208\ttest-mae:13333.6\n",
      "[405]\ttrain-mae:347.715\ttest-mae:13333.9\n",
      "[406]\ttrain-mae:346.029\ttest-mae:13334.3\n",
      "[407]\ttrain-mae:342.651\ttest-mae:13335.1\n",
      "[408]\ttrain-mae:339.922\ttest-mae:13335.5\n",
      "[409]\ttrain-mae:336.434\ttest-mae:13336.7\n",
      "[410]\ttrain-mae:332.805\ttest-mae:13337\n",
      "[411]\ttrain-mae:330.038\ttest-mae:13336.9\n",
      "[412]\ttrain-mae:327.87\ttest-mae:13336.3\n",
      "[413]\ttrain-mae:325.233\ttest-mae:13337.3\n",
      "[414]\ttrain-mae:322.736\ttest-mae:13335.9\n",
      "[415]\ttrain-mae:321.756\ttest-mae:13336\n",
      "[416]\ttrain-mae:319.879\ttest-mae:13337.7\n",
      "[417]\ttrain-mae:318.674\ttest-mae:13338\n",
      "[418]\ttrain-mae:313.43\ttest-mae:13338.5\n",
      "[419]\ttrain-mae:310.482\ttest-mae:13339.2\n",
      "[420]\ttrain-mae:308.762\ttest-mae:13339.2\n",
      "[421]\ttrain-mae:304.385\ttest-mae:13340.1\n",
      "[422]\ttrain-mae:301.359\ttest-mae:13339.2\n",
      "[423]\ttrain-mae:298.531\ttest-mae:13337.9\n",
      "[424]\ttrain-mae:295.662\ttest-mae:13338.8\n",
      "[425]\ttrain-mae:292.535\ttest-mae:13340.9\n",
      "[426]\ttrain-mae:289.754\ttest-mae:13341.9\n",
      "[427]\ttrain-mae:286.881\ttest-mae:13341.9\n",
      "[428]\ttrain-mae:283.374\ttest-mae:13341.3\n",
      "[429]\ttrain-mae:281.178\ttest-mae:13340.7\n",
      "[430]\ttrain-mae:278.963\ttest-mae:13340.6\n",
      "[431]\ttrain-mae:276.709\ttest-mae:13339.5\n",
      "[432]\ttrain-mae:273.606\ttest-mae:13339\n",
      "[433]\ttrain-mae:270.453\ttest-mae:13338.4\n",
      "[434]\ttrain-mae:267.871\ttest-mae:13338.3\n",
      "[435]\ttrain-mae:265.302\ttest-mae:13337.5\n",
      "[436]\ttrain-mae:264.483\ttest-mae:13338.4\n",
      "[437]\ttrain-mae:263.082\ttest-mae:13338.7\n",
      "[438]\ttrain-mae:259.867\ttest-mae:13338.4\n",
      "[439]\ttrain-mae:257.047\ttest-mae:13340.3\n",
      "[440]\ttrain-mae:254.076\ttest-mae:13339.2\n",
      "[441]\ttrain-mae:251.494\ttest-mae:13339.5\n",
      "[442]\ttrain-mae:249.732\ttest-mae:13339.1\n",
      "[443]\ttrain-mae:248.382\ttest-mae:13338.5\n",
      "[444]\ttrain-mae:246.64\ttest-mae:13338.3\n",
      "[445]\ttrain-mae:245.769\ttest-mae:13337.5\n",
      "[446]\ttrain-mae:242.729\ttest-mae:13337.1\n",
      "[447]\ttrain-mae:240.792\ttest-mae:13336.3\n",
      "[448]\ttrain-mae:237.505\ttest-mae:13335.8\n",
      "[449]\ttrain-mae:236.179\ttest-mae:13335.3\n",
      "[450]\ttrain-mae:233.81\ttest-mae:13335.1\n",
      "[451]\ttrain-mae:232.27\ttest-mae:13334.3\n",
      "[452]\ttrain-mae:230.645\ttest-mae:13334.2\n",
      "[453]\ttrain-mae:228.205\ttest-mae:13333\n",
      "[454]\ttrain-mae:226.917\ttest-mae:13332.9\n",
      "[455]\ttrain-mae:224.868\ttest-mae:13332.5\n",
      "[456]\ttrain-mae:223.264\ttest-mae:13331.6\n",
      "[457]\ttrain-mae:221.419\ttest-mae:13331.8\n",
      "Stopping. Best iteration:\n",
      "[157]\ttrain-mae:2395.91\ttest-mae:13146.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "# Import 'train.csv', 'test.csv', 'submission.csv' files into pandas dataframes\n",
    "train = pd.read_csv(\"../../Data/Price prediction/train.csv\")\n",
    "test = pd.read_csv(\"../../Data/Price prediction/test.csv\")\n",
    "submission = pd.read_csv('../../Data/Price prediction/submission.csv')\n",
    "\n",
    "\n",
    "# Dropped all columns except 'store_id', 'date', 'amount'\n",
    "#\n",
    "# The major reason for this was that the data does not include any hints on the type(clothing, food, alcohol, etc)\n",
    "# of store and whether if the stores are similar types or not. Hence, removed them from both train & test.\n",
    "train = train.drop(columns=['time', 'installments', 'days_of_week', 'card_id', 'holyday'])\n",
    "test = test.drop(columns=['time', 'installments', 'days_of_week', 'card_id', 'holyday'])\n",
    "\n",
    "\n",
    "# Aggregated data into the sum of amount per each day, per store_id.\n",
    "train = train.groupby(['date', 'store_id']).agg({'amount':'sum'}).reset_index()\n",
    "test = test.groupby(['date', 'store_id']).agg({'amount':'sum'}).reset_index()\n",
    "\n",
    "\n",
    "# 'date' column was converted into datetime format for further uses\n",
    "train['date'] = pd.to_datetime(train['date'],infer_datetime_format=True)\n",
    "test['date'] = pd.to_datetime(test['date'],infer_datetime_format=True)\n",
    "\n",
    "\n",
    "# a duplicate column of 'date' was created for further uses\n",
    "train['temp_date'] = train['date']\n",
    "test['temp_date'] = test['date']\n",
    "\n",
    "\n",
    "# the 'date' column was set to index\n",
    "train.set_index(\"date\",inplace=True)\n",
    "test.set_index(\"date\",inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Then, the number of data per each store_id in the train set was counted.\n",
    "# If the store_id had less than 160 rows (= 160 days of data), it was removed from the train set.\n",
    "#\n",
    "# Since the goal of the 1st Competition was to predict the future 100 days of sales,\n",
    "# 160 days was required to split into 60 days of training (X) & 100 days of prediction (y)\n",
    "# The 'limit' 160 days was the ideal number resulted from multiple trials of training.\n",
    "counter = 0\n",
    "limit = 160\n",
    "\n",
    "print(\"Before removing stores (due to limit): \", train.shape)\n",
    "\n",
    "for x in range(train['store_id'].max()+1): # iterating through each store_id\n",
    "    if train[train['store_id']==x]['store_id'].count() >= limit:\n",
    "        counter += 1\n",
    "    else:\n",
    "        # drop rows that has total 'store_id' less than limit\n",
    "        train = train[train.store_id != x]\n",
    "\n",
    "print(\"Total # of stores that exceeds {} is {}\".format(limit, counter))\n",
    "print(\"After removing stores (due to limit): \", train.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Now, the train set was checked for any stores that was out of business and removed them from the train set.\n",
    "# If the store had no data within 5 days from 2018-07-31, it was 'assumed' to be closed.\n",
    "# (2018-07-31 was the last date stores in train data was supposed to have)\n",
    "from datetime import datetime\n",
    "\n",
    "def keep_alive_store(df):\n",
    "    \n",
    "    store_id_list = df.store_id.unique() # list of train store_id\n",
    "    yes, no = 0, 0 # yes: store has data within 5 days from 2018-07-31 / no: it doesn't\n",
    "\n",
    "    t2 = datetime.strptime('2018-07-31 00:00:00', \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    for s in store_id_list:\n",
    "        if str(df[df.store_id == s].iloc[-1]['temp_date']) == '2018-07-31 00:00:00':\n",
    "            yes += 1\n",
    "        else:\n",
    "            # t1 is the last date of data the corresponding store_id has\n",
    "            t1 = datetime.strptime(str(df[df.store_id == s].iloc[-1]['temp_date']), \"%Y-%m-%d %H:%M:%S\")\n",
    "            difference = t2 - t1\n",
    "            if difference.days <= 5:            \n",
    "                yes +=1\n",
    "            else:\n",
    "                no +=1\n",
    "                df = df[df.store_id != s] # remove stores that are 'assumed' closed\n",
    "    print(\"# of train store open/out of business: \", yes, no)\n",
    "    return df\n",
    "    \n",
    "train = keep_alive_store(train)\n",
    "\n",
    "\n",
    "\n",
    "# The same goes for the test data, but in a slightly different way.\n",
    "# If the store had no data within 7 days from 2018-03-31, it was 'assumed' to be closed.\n",
    "# (2018-03-31 was the last date stores in test data was supposed to have)\n",
    "store_id_list = test.store_id.unique() # list of test store_id\n",
    "yes, no = 0, 0 # yes: store has data within 7 days from 2018-03-31 / no: it doesn't\n",
    "closed_test_store = []\n",
    "\n",
    "for s in store_id_list:\n",
    "    t2 = datetime.strptime('2018-03-31 00:00:00', \"%Y-%m-%d %H:%M:%S\")\n",
    "    t1 = datetime.strptime(str(test[test.store_id == s].iloc[-1]['temp_date']), \"%Y-%m-%d %H:%M:%S\")\n",
    "    difference = t2 - t1\n",
    "    \n",
    "    if difference.days <= 7:\n",
    "        yes+=1\n",
    "    else:\n",
    "        no+=1\n",
    "        print(test[test.store_id == s].iloc[-1]['temp_date'])\n",
    "        closed_test_store.append(s)\n",
    "print(\"# of test store open/out of business: \", yes, no)\n",
    "# Note that this time, closed stores were not dropped (obviously) and saved into 'closed_test_store' array.\n",
    "\n",
    "\n",
    "\n",
    "# Finally, each train & test data was passed into 'reform_data(df, isTrain)'\n",
    "# With each 'store_id' grouped into a new dataframe, any missing dates were filled with the amount 0\n",
    "# Then bunch of new columns were added to prepare for training/predicting:\n",
    "# such as the moving averages, y value(the future 100days), mean, median, sum, etc.\n",
    "# But they will be returned as an array, then converted into a dataframe later.\n",
    "\n",
    "def reform_data(df, isTrain):\n",
    "    store_id_list = df.store_id.unique() # list of store_id\n",
    "    x_array = [] # array to return\n",
    "\n",
    "    for s in store_id_list: # iterate through each store_id\n",
    "        store = df[df.store_id == s]\n",
    "        \n",
    "        # Filling missing dates with value of 0\n",
    "        store = store.asfreq('D', fill_value=0)\n",
    "        store['temp_date'] = store.index\n",
    "        store['store_id'] = s\n",
    "        \n",
    "        # Moving Average columns were added\n",
    "        store['MA7'] = store['amount'].rolling('7D').mean()\n",
    "        store['MA15'] = store['amount'].rolling('15D').mean()\n",
    "        store['MA30'] = store['amount'].rolling('30D').mean()\n",
    "\n",
    "        # For the train dataframe, the last 100 days were cut off and the sum was stored as the 'y' value.\n",
    "        # And the remaining data was stored into the dataframe 'store_x' to become the training data.\n",
    "        if isTrain:\n",
    "            store_y = store.last('100D') # last 100 days of store data\n",
    "            y = store_y.amount.sum()\n",
    "            store_x = store[store.temp_date < store_y.iloc[0].temp_date] # data except last 100 days\n",
    "        # For the test dataframe, all data was kept as 'store_x'.\n",
    "        # Of course the 'y' is 0 here because that's to be predicted later on.\n",
    "        else:\n",
    "            y = 0\n",
    "            store_x = store[:]\n",
    "            \n",
    "        new_data = [] # array for each store's new data\n",
    "        new_data.append(s) # store_id\n",
    "        new_data.append(y) # total sum of last 100 days (answer)\n",
    "\n",
    "        new_data.append(store_x.amount.mean()) # mean of amount\n",
    "        new_data.append(store_x.amount.median()) # median of amount\n",
    "        \n",
    "        new_data.append(store_x.last('7D').amount.mean()) # mean of amount (last 7 days)\n",
    "        new_data.append(store_x.last('15D').amount.mean()) # mean of amount (last 15 days)\n",
    "        new_data.append(store_x.last('30D').amount.mean()) # mean of amount (last 30 days)\n",
    "        \n",
    "        new_data.append(store_x.last('7D').amount.median()) # median of amount (last 7 days)\n",
    "        new_data.append(store_x.last('15D').amount.median()) # median of amount (last 15 days)\n",
    "        new_data.append(store_x.last('30D').amount.median()) # median of amount (last 30 days)\n",
    "        \n",
    "        new_data.append(store_x.last('7D').amount.sum()) # sum of amount (last 7 days)\n",
    "        new_data.append(store_x.last('15D').amount.sum()) # sum of amount (last 15 days)\n",
    "        new_data.append(store_x.last('30D').amount.sum()) # sum of amount (last 30 days)\n",
    "        \n",
    "        new_data.append(store_x.last('7D').MA7.mean()) # mean of Moving Average of 7D (last 7 days)\n",
    "        new_data.append(store_x.last('15D').MA7.mean()) # mean of Moving Average of 7D (last 15 days)\n",
    "        new_data.append(store_x.last('30D').MA7.mean()) # mean of Moving Average of 7D (last 30 days)\n",
    "        new_data.append(store_x.last('7D').MA15.mean()) # mean of Moving Average of 15D (last 7 days)\n",
    "        new_data.append(store_x.last('15D').MA15.mean()) # mean of Moving Average of 15D (last 15 days)\n",
    "        new_data.append(store_x.last('30D').MA15.mean()) # mean of Moving Average of 15D (last 30 days)\n",
    "        new_data.append(store_x.last('7D').MA30.mean()) # mean of Moving Average of 30D (last 7 days)\n",
    "        new_data.append(store_x.last('15D').MA30.mean()) # mean of Moving Average of 30D (last 15 days)\n",
    "        new_data.append(store_x.last('30D').MA30.mean()) # mean of Moving Average of 30D (last 30 days)\n",
    "        \n",
    "        x_array.append(new_data) # Append the 'new_data' array in to 'x_array'\n",
    "        \n",
    "    return x_array\n",
    "\n",
    "reformed_train = reform_data(train, True) # train data with new values\n",
    "reformed_test = reform_data(test, False) # test data with new values\n",
    "\n",
    "\n",
    "# Now the returned array is back to its dataframe form with columns names.\n",
    "# t =&gt; train / r_test =&gt; test\n",
    "t = pd.DataFrame(reformed_train, columns=['store_id', 'y', 'mean', 'median', '7mean', '15mean', '30mean', \n",
    "                                         '7median', '15median', '30median',  '7sum', '15sum', '30sum', \n",
    "                                         '7ma7mean', '15ma7mean', '30ma7mean',  '7ma15mean', '15ma15mean',\n",
    "                                         '30ma15mean',  '7ma30mean', '15ma30mean', '30ma30mean'])\n",
    "r_test = pd.DataFrame(reformed_test, columns=['store_id', 'y', 'mean', 'median', '7mean', '15mean', '30mean', \n",
    "                                         '7median', '15median', '30median',  '7sum', '15sum', '30sum', \n",
    "                                         '7ma7mean', '15ma7mean', '30ma7mean',  '7ma15mean', '15ma15mean',\n",
    "                                         '30ma15mean',  '7ma30mean', '15ma30mean', '30ma30mean'])\n",
    "                                         \n",
    "\n",
    "# xgboost was used to train the model from train data.\n",
    "# 'train_test_split' from sklearn was used to split the train data (t)\n",
    "# into train/test with test_size as 0.1\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "col = [i for i in t.columns if i not in ['store_id','y']]\n",
    "y = 'y'\n",
    "\n",
    "train_x, train_cv, y, y_cv = train_test_split(t[col],t[y], test_size=0.1, random_state=2018)\n",
    "\n",
    "\n",
    "# The model was trained with xgboost parameters as shown below.\n",
    "# Parameters were chosen after several trials of optimization.\n",
    "#\n",
    "# ('num_rounds' & 'early_stopping_rounds' were given relatively big numbers\n",
    "# since the training doesn't take much computing power.)\n",
    "def XGB_regressor(train_X, train_y, test_X, test_y, feature_names=None, seed_val=2018, num_rounds=3000):\n",
    "    param = {}\n",
    "    param['objective'] = 'reg:linear'\n",
    "    param['eta'] = 0.05\n",
    "    param['max_depth'] = 10\n",
    "    param['silent'] = 1\n",
    "    param['eval_metric'] = 'mae'\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.7\n",
    "    param['colsample_bytree'] = 0.7\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=300)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "        \n",
    "    return model\n",
    "\n",
    "# We now have the trained model!\n",
    "model = XGB_regressor(train_X = train_x, train_y = y, test_X = train_cv, test_y = y_cv)\n",
    "\n",
    "\n",
    "# (Optional) Feature Importance can be checked to see which column affected the model more.\n",
    "# This was used for a quick check when optimizing columns.\n",
    "'''\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,18))\n",
    "xgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "# The r_test (test dataset) has to be sorted since they are mixed at the moment.\n",
    "r_test = r_test.sort_values(by='store_id')\n",
    "\n",
    "# And then passed into the model to predict the answer for the competition as 'y_test'\n",
    "# This is the answer array to be submitted... after a few adjustments.\n",
    "y_test = model.predict(xgb.DMatrix(r_test[col]), ntree_limit = model.best_ntree_limit)\n",
    "\n",
    "\n",
    "# As mentioned above the data may have missing dates in between.\n",
    "# To reflect this into 'y_test', the last two months(february, march) of test data\n",
    "# is counted per each store_id and then averaged out.\n",
    "# This is required as some stores tend to be closed often throughout the month.\n",
    "store_id_list = test.store_id.unique() # list of test store_id\n",
    "store_id_list.sort() # sort the list into order\n",
    "\n",
    "feb_march = [] # saved here\n",
    "\n",
    "for s in store_id_list:\n",
    "    mini = test[test.store_id == s]\n",
    "    march = mini[mini.temp_date >= '2018-03-01']['temp_date'].count()\n",
    "    feb = mini[mini.temp_date >= '2018-02-01']['temp_date'].count() - march\n",
    "    feb_march.append((march+feb)/2/31)\n",
    "\n",
    "    \n",
    "# Before using the 'feb_march', the 'closed_test_store' array from above is used.\n",
    "# The store_id 'assumed' to be closed are given 0 for the future 100 day prediction.\n",
    "for c in closed_test_store:\n",
    "    y_test[c] = 0\n",
    "\n",
    "\n",
    "# At last the 'y_test' predicted from the trained model is adjusted with 'feb_march'.\n",
    "#\n",
    "# The last number 0.72 is an optimized number variable to make sure that no prediction exceeds the answer.\n",
    "# This is required as penalties are given.\n",
    "for x in range(200):\n",
    "    y_test[x] = y_test[x] * feb_march[x] * 0.72\n",
    "    \n",
    "\n",
    "# For submission, the 'y_test' is saved into the 'total_sales' column of 'submission.csv'.\n",
    "submission['total_sales'] = y_test\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
