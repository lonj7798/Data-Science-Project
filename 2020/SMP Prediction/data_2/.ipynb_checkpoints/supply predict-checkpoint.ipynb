{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "from numpy import unique\n",
    "from numpy import nan\n",
    "from numpy import array\n",
    "from numpy import savetxt\n",
    "from pandas import read_csv\n",
    "\n",
    "# split the dataset by 'chunkID', return a dict of id to rows\n",
    "def to_chunks(values, chunk_ix=1):\n",
    "    chunks = dict()\n",
    "    # get the unique chunk ids\n",
    "    chunk_ids = unique(values[:, chunk_ix])\n",
    "    # group rows by chunk id\n",
    "    for chunk_id in chunk_ids:\n",
    "        selection = values[:, chunk_ix] == chunk_id\n",
    "        chunks[chunk_id] = values[selection, :]\n",
    "        return chunks\n",
    "\n",
    "# split each chunk into train/test sets\n",
    "def split_train_test(chunks, row_in_chunk_ix=2):\n",
    "    train, test = list(), list()\n",
    "    # first 5 days of hourly observations for train\n",
    "    cut_point = 5 * 24\n",
    "    # enumerate chunks\n",
    "    for k,rows in chunks.items():\n",
    "        # split chunk rows by 'position_within_chunk'\n",
    "        train_rows = rows[rows[:,row_in_chunk_ix] <= cut_point, :]\n",
    "        test_rows = rows[rows[:,row_in_chunk_ix] > cut_point, :]\n",
    "        if len(train_rows) == 0 or len(test_rows) == 0:\n",
    "            print('>dropping chunk=%d: train=%s, test=%s' % (k, train_rows.shape, test_rows.shape))\n",
    "            continue\n",
    "        # store with chunk id, position in chunk, hour and all targets\n",
    "        indices = [1,2,5] + [x for x in range(56,train_rows.shape[1])]\n",
    "        train.append(train_rows[:, indices])\n",
    "        test.append(test_rows[:, indices])\n",
    "    return train, test\n",
    "\n",
    "# return a list of relative forecast lead times\n",
    "def get_lead_times():\n",
    "    return [1, 2 ,3, 4, 5, 10, 17, 24, 48, 72]\n",
    "\n",
    "# convert the rows in a test chunk to forecasts\n",
    "def to_forecasts(test_chunks, row_in_chunk_ix=1):\n",
    "    # get lead times\n",
    "    lead_times = get_lead_times()\n",
    "    # first 5 days of hourly observations for train\n",
    "    cut_point = 5 * 24\n",
    "    forecasts = list()\n",
    "    # enumerate each chunk\n",
    "    for rows in test_chunks:\n",
    "        chunk_id = rows[0, 0]\n",
    "        # enumerate each lead time\n",
    "        for tau in lead_times:\n",
    "            # determine the row in chunk we want for the lead time\n",
    "            offset = cut_point + tau\n",
    "            # retrieve data for the lead time using row number in chunk\n",
    "            row_for_tau = rows[rows[:,row_in_chunk_ix]==offset, :]\n",
    "            # check if we have data\n",
    "            if len(row_for_tau) == 0:\n",
    "                # create a mock row [chunk, position, hour] + [nan...]\n",
    "                row = [chunk_id, offset, nan] + [nan for _ in range(39)]\n",
    "                forecasts.append(row)\n",
    "            else:\n",
    "                # store the forecast row\n",
    "                forecasts.append(row_for_tau[0])\n",
    "    return array(forecasts)\n",
    "\n",
    "# load dataset\n",
    "dataset = read_csv('supply.csv', header=0)\n",
    "dataset.index = pd.to_datetime(dataset['Unnamed: 0'])\n",
    "dataset.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "# group data by chunks\n",
    "values = dataset.values\n",
    "chunks = to_chunks(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">dropping chunk=-3: train=(1, 32), test=(0, 32)\n",
      "Train Rows: (0,)\n",
      "Test Rows: (0,)\n"
     ]
    }
   ],
   "source": [
    "# split into train/test\n",
    "train, test = split_train_test(chunks)\n",
    "# flatten training chunks to rows\n",
    "train_rows = array([row for rows in train for row in rows])\n",
    "# print(train_rows.shape)\n",
    "print('Train Rows: %s' % str(train_rows.shape))\n",
    "# reduce train to forecast lead times only\n",
    "test_rows = to_forecasts(test)\n",
    "print('Test Rows: %s' % str(test_rows.shape))\n",
    "# save datasets\n",
    "savetxt('new/naive_train.csv', train_rows, delimiter=',')\n",
    "savetxt('new/naive_test.csv', test_rows, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
