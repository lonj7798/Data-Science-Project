{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6da11c92",
   "metadata": {},
   "source": [
    "## Diagnose Crop Diseases According to Environmental Changes\n",
    "### Dacon basic code: Resnet50 + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "595694ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ddf4c7",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4646d7c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8395061f42dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# neural network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "# neural network\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86cf385",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42081e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 10123\n",
    "\n",
    "sample_csv = pd.read_csv(f'sample_data/{sample}/{sample}.csv')\n",
    "sample_image = cv2.imread(f'sample_data/{sample}/{sample}.jpg')\n",
    "sample_json = json.load(open(f'sample_data/{sample}/{sample}.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d23d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv\n",
    "sample_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12610f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image\n",
    "plt.imshow(cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0411f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json\n",
    "sample_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a67eed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize bbox\n",
    "plt.figure(figsize=(7,7))\n",
    "points = sample_json['annotations']['bbox'][0]\n",
    "part_points = sample_json['annotations']['part']\n",
    "img = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "cv2.rectangle(\n",
    "    img,\n",
    "    (int(points['x']), int(points['y'])),\n",
    "    (int((points['x']+points['w'])), int((points['y']+points['h']))),\n",
    "    (0, 255, 0),\n",
    "    2\n",
    ")\n",
    "for part_point in part_points:\n",
    "    point = part_point\n",
    "    cv2.rectangle(\n",
    "        img,\n",
    "        (int(point['x']), int(point['y'])),\n",
    "        (int((point['x']+point['w'])), int((point['y']+point['h']))),\n",
    "        (255, 0, 0),\n",
    "        1\n",
    "    )\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354f9353",
   "metadata": {},
   "source": [
    "## Data Load\n",
    "### Calculate environment data: MinMax Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e977f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석에 사용할 feature 선택\n",
    "csv_features = ['내부 온도 1 평균', '내부 온도 1 최고', '내부 온도 1 최저', '내부 습도 1 평균', '내부 습도 1 최고', \n",
    "                '내부 습도 1 최저', '내부 이슬점 평균', '내부 이슬점 최고', '내부 이슬점 최저']\n",
    "\n",
    "csv_files = sorted(glob('sample_data/*/*.csv'))\n",
    "\n",
    "temp_csv = pd.read_csv(csv_files[0])[csv_features]\n",
    "max_arr, min_arr = temp_csv.max().to_numpy(), temp_csv.min().to_numpy()\n",
    "\n",
    "# feature 별 최대값, 최솟값 계산\n",
    "for csv in tqdm(csv_files[1:]):\n",
    "    temp_csv = pd.read_csv(csv)[csv_features]\n",
    "    temp_max, temp_min = temp_csv.max().to_numpy(), temp_csv.min().to_numpy()\n",
    "    max_arr = np.max([max_arr,temp_max], axis=0)\n",
    "    min_arr = np.min([min_arr,temp_min], axis=0)\n",
    "\n",
    "# feature 별 최대값, 최솟값 dictionary 생성\n",
    "csv_feature_dict = {csv_features[i]:[min_arr[i], max_arr[i]] for i in range(len(csv_features))}\n",
    "csv_feature_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea080ca",
   "metadata": {},
   "source": [
    "### Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1abe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제공된 sample data는 파프리카와 시설포도 2종류의 작물만 존재\n",
    "label_description = {\n",
    " '3_00_0': '파프리카_정상',\n",
    " '3_a9_1': '파프리카흰가루병_초기',\n",
    " '3_a9_2': '파프리카흰가루병_중기',\n",
    " '3_a9_3': '파프리카흰가루병_말기',\n",
    " '3_a10_1': '파프리카잘록병_초기',\n",
    " '3_a10_2': '파프리카잘록병_중기',\n",
    " '3_a10_3': '파프리카잘록병_말기',\n",
    " '3_b3_1': '칼슘결핍_초기',\n",
    " '3_b3_2': '칼슘결핍_중기',\n",
    " '3_b3_3': '칼슘결핍_말기',\n",
    " '3_b6_1': '다량원소결핍 (N)_초기',\n",
    " '3_b6_2': '다량원소결핍 (N)_중기',\n",
    " '3_b6_3': '다량원소결핍 (N)_말기',\n",
    " '3_b7_1': '다량원소결핍 (P)_초기',\n",
    " '3_b7_2': '다량원소결핍 (P)_중기',\n",
    " '3_b7_3': '다량원소결핍 (P)_말기',\n",
    " '3_b8_1': '다량원소결핍 (K)_초기',\n",
    " '3_b8_2': '다량원소결핍 (K)_중기',\n",
    " '3_b8_3': '다량원소결핍 (K)_말기',\n",
    " '6_00_0': '시설포도_정상',\n",
    " '6_a11_1': '시설포도탄저병_초기',\n",
    " '6_a11_2': '시설포도탄저병_중기',\n",
    " '6_a11_3': '시설포도탄저병_말기',\n",
    " '6_a12_1': '시설포도노균병_초기',\n",
    " '6_a12_2': '시설포도노균병_중기',\n",
    " '6_a12_3': '시설포도노균병_말기',\n",
    " '6_b4_1': '일소피해_초기',\n",
    " '6_b4_2': '일소피해_중기',\n",
    " '6_b4_3': '일소피해_말기',\n",
    " '6_b5_1': '축과병_초기',\n",
    " '6_b5_2': '축과병_중기',\n",
    " '6_b5_3': '축과병_말기',\n",
    "}\n",
    "\n",
    "label_encoder = {key:idx for idx, key in enumerate(label_description)}\n",
    "label_decoder = {val:key for key, val in label_encoder.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0137a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, files, labels=None, mode='train'):\n",
    "        self.mode = mode\n",
    "        self.files = files\n",
    "        self.csv_feature_dict = csv_feature_dict\n",
    "        self.csv_feature_check = [0]*len(self.files)\n",
    "        self.csv_features = [None]*len(self.files)\n",
    "        self.max_len = -1 * 24*6\n",
    "        self.label_encoder = label_encoder\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        file = self.files[i]\n",
    "        file_name = file.split('/')[-1]\n",
    "        \n",
    "        json_path = f'{file}/{file_name}.json'\n",
    "        image_path = f'{file}/{file_name}.jpg'\n",
    "        \n",
    "        if self.csv_feature_check[i] == 0:\n",
    "            csv_path = f'{file}/{file_name}.csv'\n",
    "            df = pd.read_csv(csv_path)\n",
    "\n",
    "            # MinMax scaling\n",
    "            for col in self.csv_feature_dict.keys():\n",
    "                df[col] = df[col] - self.csv_feature_dict[col][0]\n",
    "                df[col] = df[col] / (self.csv_feature_dict[col][1]-self.csv_feature_dict[col][0])\n",
    "            \n",
    "            # transpose to sequential data\n",
    "            csv_feature = df[self.csv_feature_dict.keys()].to_numpy()[self.max_len:].T\n",
    "            self.csv_features[i] = csv_feature\n",
    "            self.csv_feature_check[i] = 1\n",
    "        else:\n",
    "            csv_feature = self.csv_features[i]\n",
    "        \n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.resize(img, dsize=(256, 256), interpolation=cv2.INTER_AREA)\n",
    "        img = img.astype(np.float32)/255\n",
    "        img = np.transpose(img, (2,0,1))\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            with open(json_path, 'r') as f:\n",
    "                json_file = json.load(f)\n",
    "            \n",
    "            crop = json_file['annotations']['crop']\n",
    "            disease = json_file['annotations']['disease']\n",
    "            risk = json_file['annotations']['risk']\n",
    "            label = f'{crop}_{disease}_{risk}'\n",
    "            \n",
    "            return {\n",
    "                'img' : torch.tensor(img, dtype=torch.float32),\n",
    "                'csv_feature' : torch.tensor(csv_feature, dtype=torch.float32),\n",
    "                'label' : torch.tensor(self.label_encoder[label], dtype=torch.long)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'img' : torch.tensor(img, dtype=torch.float32),\n",
    "                'csv_feature' : torch.tensor(csv_feature, dtype=torch.float32)\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ff072a",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778b00e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "batch_size = 256\n",
    "class_n = len(label_encoder)\n",
    "learning_rate = 1e-4\n",
    "embedding_dim = 512\n",
    "num_features = len(csv_feature_dict)\n",
    "max_len = 24*6\n",
    "dropout_rate = 0.1\n",
    "epochs = 30\n",
    "vision_pretrain = True\n",
    "save_path = 'best_model.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4eccd9f",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0562c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = glob('sample_data/*')\n",
    "\n",
    "train = data_files[:250]\n",
    "val = data_files[250:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0099712b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train)\n",
    "val_dataset = CustomDataset(val)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=16, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, num_workers=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ccdfdb",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1045ae1",
   "metadata": {},
   "source": [
    "### Image: Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545b080b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Encoder(nn.Module):\n",
    "    def __init__(self, class_n, rate=0.1):\n",
    "        super(CNN_Encoder, self).__init__()\n",
    "        self.model = models.resnet50(pretrained=True)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        output = self.model(inputs)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fe69be",
   "metadata": {},
   "source": [
    "### Time Series: LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9c4d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Decoder(nn.Module):\n",
    "    def __init__(self, max_len, embedding_dim, num_features, class_n, rate):\n",
    "        super(RNN_Decoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(max_len, embedding_dim)\n",
    "        self.rnn_fc = nn.Linear(num_features*embedding_dim, 1000)\n",
    "        self.final_layer = nn.Linear(1000 + 1000, class_n)\n",
    "        self.dropout = nn.Dropout(rate)\n",
    "\n",
    "    def forward(self, enc_out, dec_inp):\n",
    "        hidden, _ = self.lstm(dec_inp)\n",
    "        hidden = hidden.view(hidden.size(0), -1)\n",
    "        hidden = self.rnn_fc(hidden)\n",
    "        concat = torch.cat([enc_out, hidden], dim=1) # enc_out + hidden \n",
    "        fc_input = concat\n",
    "        output = self.dropout((self.final_layer(fc_input)))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22340fc8",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10297c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2RNN(nn.Module):\n",
    "    def __init__(self, max_len, embedding_dim, num_features, class_n, rate):\n",
    "        super(CNN2RNN, self).__init__()\n",
    "        self.cnn = CNN_Encoder(embedding_dim, rate)\n",
    "        self.rnn = RNN_Decoder(max_len, embedding_dim, num_features, class_n, rate)\n",
    "        \n",
    "    def forward(self, img, seq):\n",
    "        cnn_output = self.cnn(img)\n",
    "        output = self.rnn(cnn_output, seq)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b555d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN2RNN(max_len=max_len, embedding_dim=embedding_dim, num_features=num_features, class_n=class_n, rate=dropout_rate)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30b7a95",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c36dc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a9d327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_function(real, pred):    \n",
    "    real = real.cpu()\n",
    "    pred = torch.argmax(pred, dim=1).cpu()\n",
    "    score = f1_score(real, pred, average='macro')\n",
    "    return score\n",
    "\n",
    "def train_step(batch_item, training):\n",
    "    img = batch_item['img'].to(device)\n",
    "    csv_feature = batch_item['csv_feature'].to(device)\n",
    "    label = batch_item['label'].to(device)\n",
    "    if training is True:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(img, csv_feature)\n",
    "            loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        score = accuracy_function(label, output)\n",
    "        return loss, score\n",
    "    else:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model(img, csv_feature)\n",
    "            loss = criterion(output, label)\n",
    "        score = accuracy_function(label, output)\n",
    "        return loss, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d882ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot, val_loss_plot = [], []\n",
    "metric_plot, val_metric_plot = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss, total_val_loss = 0, 0\n",
    "    total_acc, total_val_acc = 0, 0\n",
    "    \n",
    "    tqdm_dataset = tqdm(enumerate(train_dataloader))\n",
    "    training = True\n",
    "    for batch, batch_item in tqdm_dataset:\n",
    "        batch_loss, batch_acc = train_step(batch_item, training)\n",
    "        total_loss += batch_loss\n",
    "        total_acc += batch_acc\n",
    "        \n",
    "        tqdm_dataset.set_postfix({\n",
    "            'Epoch': epoch + 1,\n",
    "            'Loss': '{:06f}'.format(batch_loss.item()),\n",
    "            'Mean Loss' : '{:06f}'.format(total_loss/(batch+1)),\n",
    "            'Mean F-1' : '{:06f}'.format(total_acc/(batch+1))\n",
    "        })\n",
    "    loss_plot.append(total_loss/(batch+1))\n",
    "    metric_plot.append(total_acc/(batch+1))\n",
    "    \n",
    "    tqdm_dataset = tqdm(enumerate(val_dataloader))\n",
    "    training = False\n",
    "    for batch, batch_item in tqdm_dataset:\n",
    "        batch_loss, batch_acc = train_step(batch_item, training)\n",
    "        total_val_loss += batch_loss\n",
    "        total_val_acc += batch_acc\n",
    "        \n",
    "        tqdm_dataset.set_postfix({\n",
    "            'Epoch': epoch + 1,\n",
    "            'Val Loss': '{:06f}'.format(batch_loss.item()),\n",
    "            'Mean Val Loss' : '{:06f}'.format(total_val_loss/(batch+1)),\n",
    "            'Mean Val F-1' : '{:06f}'.format(total_val_acc/(batch+1))\n",
    "        })\n",
    "    val_loss_plot.append(total_val_loss/(batch+1))\n",
    "    val_metric_plot.append(total_val_acc/(batch+1))\n",
    "    \n",
    "    if np.max(val_metric_plot) == val_metric_plot[-1]:\n",
    "        torch.save(model, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45b56cd",
   "metadata": {},
   "source": [
    "## Training Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306217c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(loss_plot, label='train_loss')\n",
    "plt.plot(val_loss_plot, label='val_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title(\"Loss\", fontsize=25)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1794bc9e",
   "metadata": {},
   "source": [
    "## Guessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca77585c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataset):\n",
    "    model.eval()\n",
    "    tqdm_dataset = tqdm(enumerate(dataset))\n",
    "    training = False\n",
    "    results = []\n",
    "    answer = []\n",
    "    for batch, batch_item in tqdm_dataset:\n",
    "        img = batch_item['img'].to(device)\n",
    "        seq = batch_item['csv_feature'].to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(img, seq)\n",
    "        output = torch.tensor(torch.argmax(output, axis=-1), dtype=torch.int32).cpu().numpy()\n",
    "        results.extend(output)\n",
    "        answer.extend(batch_item['label'])\n",
    "    return results, answer\n",
    "\n",
    "preds, answer = predict(val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bbd977",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f25c82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = np.array([label_description[label_decoder[int(val)]] for val in answer])\n",
    "preds = np.array([label_description[label_decoder[int(val)]] for val in preds])\n",
    "\n",
    "new_crosstab = pd.crosstab(answer, preds, rownames=['answer'], colnames=['preds'])\n",
    "new_crosstab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
